<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    background-color: white;
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
  kbd {
    color: #121212;
  }
</style>
<title>CS 184 Path Tracer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2023</h1>
<h1 align="middle">Project 3-1: Path Tracer</h1>
<h2 align="middle">Yifan Yin & Jared Basilio</h2>

<!-- Add Website URL -->
<h2 align="middle">Website URL: <a href="https://cal-cs184-student.github.io/hw-webpages-sp24-JaredBasilio/hw3/index.html">Website Link</a></h2>

<br><br>


<div align="center">
  <table style="width=100%">
      <tr>
          <td align="middle">
          <img src="images/example_image.png" width="480px" />
          <figcaption align="middle">Results Caption: my bunny is the bounciest bunny</figcaption>
      </tr>
  </table>
</div>
<!-- 
<p>All of the text in your write-up should be <em>in your own words</em>. If you need to add additional HTML features to this document, you can search the <a href="http://www.w3schools.com/">http://www.w3schools.com/</a> website for instructions. To edit the HTML, you can just copy and paste existing chunks and fill in the text and image file names appropriately.</p>
<o>The website writeup is intended to be a self-contained walkthrough of the assignment: we want this to be a piece of work which showcases your understanding of relevant concepts through both mesh images as well as written explanations about what you did to complete each part of the assignment. Try to be as clear and organized as possible when writing about your own output files or extensions to the assignment. We want to understand what you've achieved and how you've done it!</p> 
<p>If you are well-versed in web development, feel free to ditch this template and make a better looking page.</p>


<p>Here are a few problems students have encountered in the past. Test your website on the instructional machines early!</p>
<ul>
<li>Your main report page should be called index.html.</li>
<li>Be sure to include and turn in all of the other files (such as images) that are linked in your report!</li>
<li>Use only <em>relative</em> paths to files, such as <pre>"./images/image.jpg"</pre>
Do <em>NOT</em> use absolute paths, such as <pre>"/Users/student/Desktop/image.jpg"</pre></li>
<li>Pay close attention to your filename extensions. Remember that on UNIX systems (such as the instructional machines), capitalization matters. <pre>.png != .jpeg != .jpg != .JPG</pre></li>
<li>Be sure to adjust the permissions on your files so that they are world readable. For more information on this please see this tutorial: <a href="http://www.grymoire.com/Unix/Permissions.html">http://www.grymoire.com/Unix/Permissions.html</a></li>
<li>And again, test your website on the instructional machines early!</li>
</ul>


<p>Here is an example of how to include a simple formula:</p>
<p align="middle"><pre align="middle">a^2 + b^2 = c^2</pre></p>
<p>or, alternatively, you can include an SVG image of a LaTex formula.</p>

<div> -->

<h2 align="middle">Overview</h2>
<p>
    We implement the basic lighting rendering pipelines starting from ray generation and scene intersection to better sampling and lighting techniques.
</p>
<br>

<h2 align="middle">Part 1: Ray Generation and Scene Intersection (20 Points)</h2>
<!-- Walk through the ray generation and primitive intersection parts of the rendering pipeline.
Explain the triangle intersection algorithm you implemented in your own words.
Show images with normal shading for a few small .dae files. -->

<h3>
  Walk through the ray generation and primitive intersection parts of the rendering pipeline.
</h3>
<p>
    <h4>Ray Generation</h4>
    Ray generation first requires translating the provided normalize image coordinates
     from image space to camera space. 
    We do this by subtracting each coordinate by \(0.5 \) then multiplying the \(x \) coordinate by 
    \(\tan {\frac{hFov}{2}} \) and then multiplying the \(y \) coordinate by \(\tan {\frac{vFov}{2}} \). We reduce 
    our coordinates to get the center of the grid square.

    Given these transformed coordinates, we can turn this into the direction of the ray in camera space 
    where the \(z \) value is initially \(-1 \). Multiply this direction by the camera-to-world rotation matrix 
    (<code>c2w</code> in <code>camera.h</code>) and create a Ray object using the current position of the camera and 
    unit vector of our new 3D object. Set the bounds of our ray (<code>min_t</code>, <code>max_t</code>) to our clipping planes 
    <code>nClip</code> and <code>fClip</code>.

    We then uniformly sample from the provided pixel coordinate <code>num_samples</code> times, each time generating a ray adding 
    the estimated radiance given the <code>est_radiance_global_illumination</code> function to the overall radiance. We use a 
    MC estimator that is the radiance per sample and update our pixel in our sample buffer with this value. Set the sample count buffer at \(x + y * width \) to the number of samples.

    <br /><br />
    <h4>Primitive intersections</h4>
    We now need to check if any triangles or spheres in the space intersect the ray to apply some seperate value and not have the ray pass through the object. 
    <h5>Triangle Intersections</h5>
    We implement the <code>has_intersection</code> function that takes in a ray \(r \) an returns a boolean if that ray intersects a triangle. 
    This calculates a multitude of values listed below:
    \[t = \frac{((\text ray \space \text origin - p_1) \times (p_2 - p_1)) \cdot (p_3 - p_1)}{(\text ray \space \text direction \times (p_3 - p_1)) \cdot (p_2 - p_1)} \]
    \[b_1 = \frac{(\text ray \space \text direction \times (p_3 - p_1)) \cdot (\text ray \space \text origin - p_1)}{(\text ray \space \text direction \times (p_3 - p_1)) \cdot (p_2 - p_1)} \]
    \[b_2 = \frac{(\text ray \space \text origin \times (p_2 - p_1)) \cdot \text ray \space \text direction}{(\text ray \space \text direction \times (p_3 - p_1)) \cdot (p_2 - p_1)} \]
    \[b_0 = 1 - b_1 - b_2 \]
    where \(p \) are the vertices off the triangle. These values derive from the Möller–Trumbore intersection algorithm. If the \(t \) value 
    is not within bounds of the ray or the values of \(b \) are outside the range \([0,1] \) we return false. 
    The <code>intersection</code> function sets our <code>max_t</code> of the ray to this \(t \) value if it does not intersect. Additionally an intersection object is 
    set such that the \(t \) value is the found \(t \) value, the normal at point of intersection is unit vector of the weighted sum of \(b \) values, the primitive is the triangle, and the bsdf is found.
    <h5>Sphere Intersections</h5>
    Since the triangle intersection logic requires vertices (not a sphere technically does not have), we utilize a different logic 
    that utilizes the minimum and maximum \(t \) values of the ray. We calculate the following:
    \[a = \text ray \space \text direction \cdot \text ray \space \text direction\]
    \[b = 2*((\text ray \space \text origin - \text sphere \space \text origin) \cdot \text ray \space \text direction)\]
    \[c = (\text ray \space \text origin - \text sphere \space \text origin) \cdot (\text ray \space \text origin - \text sphere \space \text origin) - \text minimum \space \text t\]
    \[\Delta  = b^2 - 4ac\]
    We can think of these formulas as the a,b, an c in the quadratic formula. 
    If \(\Delta \) is equal to 0, there is no + or - in the quadratic formula, our ray is tangent to the sphere and there is only one intersection. We can just see if the resulting quadratic formula value \(t \) 
    is within our bounds. If it is we set the minimum t to this value and return saying it does intersect. If the \(\Delta \) is greater 
    than 0 we account for two solutions to quadratic formula and see if either of them are within our bounds. If they are we set the minimum t to this value.
    Otherwise the ray does not intersect since in the quadratic formula this would be imaginary.
    <code>intersect</code> does this check again and sets the values of <code>max_t</code> of the ray to the minimum value, sets \(t \) to \(t_1 \), 
    sets \(n \) to the unit vector of \(\text ray \space \text origin  + (\text minimum \space \text t)* \text ray \space \text direction - \text sphere \space \text origin\) and the bsdf.
</p>
<br>

<h3>
  Explain the triangle intersection algorithm you implemented in your own words.
</h3>
<p>
    The Moller Trumbore Algorithm is the driving algorithm we used for our implementation.  It starts by finding two vectors that represent two sides of the triangle, then calculates a 
    perpendicular vector to the ray and one of the triangle's sides. By using some math, it checks if the 
    ray and the triangle are likely to intersect, and if they're not parallel, it finds where they cross paths. 
    Next, it ensures that this intersection point is actually inside the triangle. Finally, it confirms that this
     intersection point is in front of the ray's starting point.
</p>
<br>

<h3>
  Show images with normal shading for a few small .dae files.
</h3>
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/part_1/bunny_p1.png" align="middle" width="400px"/>
        <figcaption>CBBunny.dae</figcaption>
      </td>
      <td>
        <img src="images/part_1/coil_p1.png" align="middle" width="400px"/>
        <figcaption>CBcoil.dae</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part_1/dragon_p1.png" align="middle" width="400px"/>
        <figcaption>CBdragon.dae</figcaption>
      </td>
      <td>
        <img src="images/part_1/sphere_p1.png" align="middle" width="400px"/>
        <figcaption>Cbspheres.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>


<h2 align="middle">Part 2: Bounding Volume Hierarchy (20 Points)</h2>
<!-- Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis. -->

<h3>
  Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
</h3>
<p>
    Our BVH construction algorithm consists of three major steps: constructing the BVH, intersecting the bounding box, and intersecting the BVH.
    <h4>Constructing the BVH</h4>
    Given a list of primitives, expand the bounding box such that it will fit all the primitives. Now with our bounding box, we create 
    a new <code>BVHNode</code> If there are no more than max_leaf_size primitives in the list, the node we just 
    created is a leaf node and we should update its start and end iterators appropriately. This check is our base case. Otherwise, we need to divide the primitives into a "left" and "right" collection.
    To do this, we first split along all of the axises (X,Y,Z) by comparing the centroid of each primitive to the centroid of the bounding box we found earlier.
    Then create a heuristic that selects the axis giving us the most benefit. This is simply if the product of 
    an axis's left and right values is greater than another.
    We then partition the array so that elements of the left child are placed on the left and all of the elements of the right child are place on the right.
    We recursively call this function to do this again until we reach our base case.
    You can think of this similar to merge sort or a divide and conquer approach.
    <h4>Intersecting the bounding box</h4>
    To intersect the bounding box, we simply get the min values of the axis's and check if these values are logical. More formally for our min values we do:
    \[\frac{\text min \space \text corner_{axis} - \text ray \space \text origin_{axis}}{\text ray \space \text direction_{axis}} \]
    \[\frac{\text max \space \text corner_{axis} - \text ray \space \text origin_{axis}}{\text ray \space \text direction_{axis}} \]
    <h4>Interesecting the BVH</h4>
    Intersecting the BVH has two functions, first to check if we can intersect and second actually intersecting.
    To check if we can intersect, we get the bounding box of the provided node and check if the bounding box intersects the provided ray. 
    If it doesn't, we can recursively check if the left or right child of the provided node intersects. If the bound box and provided node do intersect, 
    we check if the node is a leaf. If it is a leaf we iterate through the scene primitives and increment the total count of intersections and check if the primitive has an intersection with our ray. If any of them do, we can say that the node and ray intersects. 
    For actually intersecting, if the node is a leaf we can do the same thing and iterate through the scene primitives, incrementing total intersects and intersecting the primitive with the ray. Otherwise recursively call the intersection function on the left and right child. We return True or False if there is an intersection. 
</p>

<h3>
  Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/part_2/beetle_p2.png" align="middle" width="400px"/>
        <figcaption>beetle.dae</figcaption>
      </td>
      <td>
        <img src="images/part_2/cow_p2.png" align="middle" width="400px"/>
        <figcaption>cow.dae</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part_2/peter_p2.png" align="middle" width="400px"/>
        <figcaption>peter.dae</figcaption>
      </td>
      <td>
        <img src="images/part_2/teapot_p2.png" align="middle" width="400px"/>
        <figcaption>teapot.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis.
</h3>
<p>
    In complex figures, when rendering <code>CBLucy.dae</code> with BVH acceleration, BVH traced 287604 rays with an average speed of 1.5787 million rays per second and averaging 2.445074 intersection tests per ray.
    Without BVH acceleration, BVH traced 295980 rays, an average speed 1.5194 million rays per second and averaged 2.395236 intersection tests per ray.
    In less complex figures, when rendering <code>teapot.dae</code> with BVH acceleration, BVH traced 290328 rays with and average speed 1.7142 million rays per second and averaging 5.722404 intersection tests per ray.
    Without BVH acceleration in less complex figures, when rendering <code>teapot.dae</code> without BVH acceleration, BVH traced 278633 rays with an average speed of 1.6659 million rays per second and averaging 5.794755 intersection tests per ray.
    Comparing the two techniques, BVH acceleration we had more intersections and rays per second than without BVH acceleration. However we do trace more rays without the optimization technique.
</p>
<br>

<h2 align="middle">Part 3: Direct Illumination (20 Points)</h2>
<!-- Walk through both implementations of the direct lighting function.
Show some images rendered with both implementations of the direct lighting function.
Focus on one particular scene with at least one area light and compare the noise levels in soft shadows when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, not uniform hemisphere sampling.
Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis. -->

<h3>
  Walk through both implementations of the direct lighting function.
</h3>
<p>
    Direct lighting has two modes in this assignment, with uniform hemisphere sampling or importance sampling. Before those we have to provide the capability to 
    diffuse material that reflects incoming light equally in all directions.
    We First Implemented the <code>f</code> function to return the reflectance given the \(w_o \) and \(w_i \), the outgoing light direction and incoming light direction.
    Since this is uniform, we just have to just return \(\frac{reflectance}{2 \pi} \). We then implement zero-bounce illumination,
    which is when the light does not bounce off anything in the scene and is only the light that comes from the light source itself. 
    This function takes in a ray and an intersection object and simply (in our case) return the emission of the bsect of the intersection. We now are split into two parts 
    Uniform Hemisphere Sampling and Importance Sampling.
    <h4>Uniform Hemisphere Sampling</h4>
    <code>estimate_direct_lighting_hemisphere</code> takes in a ray and an intersection and returns the pathtracing vector. Utilizing the global \(L \) value, we add to this 
    sampling \(n \) times.
    In this function we sample the incoming light direction from a <code>hemisphereSampler</code> object and create a new ray where the origin is at <code>hit_p</code>, the direction at the sampled direction put into a 3x3 matrix, and a depth of the ray - 1.
    We set the <code>min_t</code> of this ray to <code>EPS_F</code>. Using the intersection, we find the BSDF using <code>w_out</code> and <code>w_i</code>.
    If the new ray intersects the BVH, our light is emission of the new intersection, otherwise its the sample direction of the new ray. Using the retrieved values we can add the following to our Light:
    \[BSDF*L_i*(\text intersecion \space \text normal \cdot \text new \space \text ray \space \text direction) * 2\]
    After sampling, we weight our light out by \(\frac{2 \pi}{samples} \) since we are in a hemisphere. We modify <code>est_radiance_global_illumination</code> to add a one bounce radiance to our zero bounce and have the one bounce radiance return the 
    <code>estimate_direct_lighting_hemisphere</code> function we made. This is later changed to check if our <code>direct_hemisphere_sample</code> boolean is set to treu to use, otherwise we use importance sampling.
    <h4>Importance Sampling</h4>
    The <code>estimate_direct_lighting_importance</code> function is very different, for each light we check if the light is a delta light. 
    If it is, we increment \(L \) by the following:
    \[\frac{BSDF*L_i*(\text intersection \space \text normal \cdot \text new \space \text ray \space \text direction)}{2*pdf} \]
    This is similar to the uniform hemisphere function but rather the we sample from the light rather than the hemisphere sampler and default to it if the new ray does not intersect our primitive. The <code>max_t</code> of our new ray is the <code>dist_to_light</code> - EPS_F.
    If we are not a delta light, we sample <code>ns_area_light</code> times with the <code>sample_L</code> function like before and just get the mean sample.
</p>

<h3>
  Show some images rendered with both implementations of the direct lighting function.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <!-- Header -->
    <tr align="center">
      <th>
        <b>Uniform Hemisphere Sampling</b>
      </th>
      <th>
        <b>Light Sampling</b>
      </th>
    </tr>
    <br>
    <tr align="center">
      <td>
        <img src="images/part_3/CBbunny_H_64_32.png" align="middle" width="400px"/>
        <figcaption>CBbunny.dae</figcaption>
      </td>
      <td>
        <img src="images/part_3/CBbunny_64_32.png" align="middle" width="400px"/>
        <figcaption>CBbunny.dae</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part_3/CBspheres_lambertian_H_64_32.png" align="middle" width="400px"/>
        <figcaption>CBspheres_lambertian.dae</figcaption>
      </td>
      <td>
        <img src="images/part_3/CBspheres_lambertian_64_32.png" align="middle" width="400px"/>
        <figcaption>CBspheres_lambertian.dae</figcaption>
      </td>
    </tr>
    <br>
    <br>
  </table>
</div>
<br>

<h3>
  Focus on one particular scene with at least one area light and compare the noise levels in <b>soft shadows</b> when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, <b>not</b> uniform hemisphere sampling.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/part_3/dragon_1_1.png" align="middle" width="200px"/>
        <figcaption>1 Light Ray (dragon.dae)</figcaption>
      </td>
      <td>
        <img src="images/part_3/dragon_4_1.png" align="middle" width="200px"/>
        <figcaption>4 Light Rays (dragon.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part_3/dragon_16_1.png" align="middle" width="200px"/>
        <figcaption>16 Light Rays (dragon.dae)</figcaption>
      </td>
      <td>
        <img src="images/part_3/dragon_64_1.png" align="middle" width="200px"/>
        <figcaption>64 Light Rays (dragon.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<p>
    Increasing the light rays decreases the noise, but as we become greater the visual improvement becomes harder to classify.
</p>
<br>

<h3>
  Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis.
</h3>
<p>
    Uniform Hemisphere sampling provides a grainier render than lighting sampling. 
    This is becuase uniform hemisphere sampling utilizes an unbiased approach to global illumination. On the other hand, 
    direct render sampling samples from the lights and uses some average of the light or a more intelligent calculation to determine light values. 
    We also render more around the light, ignoring darker spots.
</p>
<br>


<h2 align="middle">Part 4: Global Illumination (20 Points)</h2>
<!-- Walk through your implementation of the indirect lighting function.
Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
You will probably want to use the instructional machines for the above renders in order to not burn up your own computer for hours. -->

<h3>
  Walk through your implementation of the indirect lighting function.
</h3>
<p>
    We first implemented <code>sample_f</code> which samples the incoming direction \(w_i \) from the provided pdf using the <code>get_sample</code> function 
    and then calls and returns the <code>f</code> function that we implemented in part 3. Then we implement the 
    <code>at_least_one_bounce_radiance</code> function to return the light given the depth. If our depth is 1, we can just return the 
    output of the <code>one_bounce_radiance</code> function. We have to first generate a ray and calculate the radiance. If the new ray intersects the bvh, 
    we can recrusively call the <code>one_bounce_radiance</code> function and add it to the light based on the following function (this is similar to part 3):
    \[\frac{BSDF*L_i*(\text intersecion \space \text normal \cdot \text new \space \text ray \space \text direction)}{pdf}\]. Using the 
    russian roulette technique, we can use the probability \(0.3 \) for chance of bouncing. If the new ray intersects 
    we check if the depth of the ray is the max depth or one less than the max depth. If so, we can recursively call <code>at_least_one_bounce_radiance</code> and add the result in the following way:
    \[\frac{BSDF*L_i*(\text intersecion \space \text normal \cdot \text new \space \text ray \space \text direction)}{pdf * 2}\]
    Otherwise, we call add the result this way:
    \[\frac{\frac{BSDF*L_i*(\text intersecion \space \text normal \cdot \text new \space \text ray \space \text direction)}{pdf}}{0.6}\]
    The 0.6 is just the russian roullette probability 0.3 multiplied by 2.
</p>
<br>

<h3>
  Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/part_4/spheres_direct.png" align="middle" width="400px"/>
        <figcaption>CBspheres_lambertian.dae (direct lighting)</figcaption>
      </td>
      <td>
        <img src="images/part_4/spheres_indirect.png" align="middle" width="400px"/>
        <figcaption>CBspheres_lambertian.dae (indirect lighting)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/part_4/spheres_only_direct.png" align="middle" width="400px"/>
        <figcaption>Only direct illumination (spheres.dae)</figcaption>
      </td>
      <td>
        <img src="images/part_4/spheres_only_indirect.png" align="middle" width="400px"/>
        <figcaption>Only indirect illumination (spheres.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    In only indirect illumination, the light at the top of the scene is absent because it is considers an indirect light source but light coming from the walls or the objects appear. 
    On the other hand, the lighting in only direct illumination only shows the light coming from the top and none from reflections.
</p>
<br>

<h3>
  For CBbunny.dae, render the mth bounce of light with max_ray_depth set to 0, 1, 2, 3, 4, and 5 (the -m flag), and isAccumBounces=false. Explain in your writeup what you see for the 2nd and 3rd bounce of light, and how it contributes to the quality of the rendered image compared to rasterization. Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/part_4/bunny_0.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 0 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/part_4/bunny_1.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 1 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part_4/CBbunny_O_2.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 2 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/part_4/CBbunny_O_3.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 3 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part_4/CBbunny_O_4.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 4 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/part_4/CBbunny_O_5.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 5 (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
   In 2 and 3 we see reflectance from the floor and walls onto the bunny, this produces more of the global illumination that we are looking for.
</p>
<br>

<h3>
  For CBbunny.dae, output the Russian Roulette rendering with max_ray_depth set to 0, 1, 2, 3, 4, and 100(the -m flag). Use 1024 samples per pixel.
</h3>
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/part_4/spheres_RR_0.png" align="middle" width="400px"/>
        <figcaption>Max Ray Depth 0 (CBSphere_lambertian.dae)</figcaption>
      </td>
      <td>
        <img src="images/part_4/spheres_RR_1.png" align="middle" width="400px"/>
        <figcaption>Max Ray Depth 1 (CBSphere_lambertian.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part_4/spheres_RR_2.png" align="middle" width="400px"/>
        <figcaption>Max Ray Depth 2 (CBSphere_lambertian.dae)</figcaption>
      </td>
      <td>
        <img src="images/part_4/spheres_RR_3.png" align="middle" width="400px"/>
        <figcaption>Max Ray Depth 3 (CBSphere_lambertian.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part_4/spheres_RR_100.png" align="middle" width="400px"/>
        <figcaption>Max Ray Depth 100 (CBSphere_lambertian.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
  The quality of the shadows are not as intense as the rays increase.
</p>

<h3>
  Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/part_4/spheres_7_1.png" align="middle" width="400px"/>
        <figcaption>1 sample per pixel (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/part_4/spheres_7_2.png" align="middle" width="400px"/>
        <figcaption>2 samples per pixel (example1.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part_4/spheres_7_4.png" align="middle" width="400px"/>
        <figcaption>4 samples per pixel (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/part_4/spheres_7_8.png" align="middle" width="400px"/>
        <figcaption>8 samples per pixel (example1.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part_4/spheres_7_16.png" align="middle" width="400px"/>
        <figcaption>16 samples per pixel (example1.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part_4/spheres_7_1024.png" align="middle" width="400px"/>
        <figcaption>1024 samples per pixel (example1.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    As we increase the samples, we lose the grain from the photos.
</p>
<br>


<h2 align="middle">Part 5: Adaptive Sampling (20 Points)</h2>
<!-- Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
Pick one scene and render it with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth. -->

<h3>
  Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
</h3>
<p>    
  Adaptive sampling is a technique used in computer graphics, particularly in rendering, to 
  intelligently allocate computational resources for generating images. 
  Instead of uniformly sampling every pixel in an image, adaptive sampling adjusts the sampling rate based on certain criteria, 
  such as the complexity of the scene or the level of detail required. This approach aims to focus computational 
  effort where it is most needed, improving the efficiency of the rendering process while maintaining image quality. In our 
  implementation, we iterate \(\frac{numSamples}{samplesPerBatch} \) times.The \(s_1 \) and \(s_2 \) values are the illumination of the est radiance and the squared illumination of the est radiance. 
  We generate a ray by turning a sampled pixel to image space and calling <code>generate_ray</code>. We have to set the depth of this ray to the maximum ray depth. Using 
  <code>est_radiance_global_illumination</code> on the ray, we can generate the estimated radiance and add this to the overall raiance.Each time checking if the following holds:
  \[mean = \frac{s_1}{samples} \]
  \[var = \frac{\frac{s_2 - s_1 ^ 2}{samples}}{samples - 1} \]
  \[\frac{1.96*\sqrt{var}}{\sqrt{samples}} \leq maxTolerance*mean\]
  If this check holds, we can prematurely stop sampling. The estimated radiance become the average of the overall radiance per sample. Like before, we update the pixel with the 
  estimated radiance and set the \(x + y*width \) value to the number of samples.
</p>
<br>

<h3>
  Pick two scenes and render them with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/part_5/bunny_p5.png" align="middle" width="400px"/>
        <figcaption>Rendered image (CBBunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/part_5/bunny_p5_rate.png" align="middle" width="400px"/>
        <figcaption>Sample rate image (CBBunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part_5/spheres_p5.png" align="middle" width="400px"/>
        <figcaption>Rendered image (CBspheres_lambertian.dae)</figcaption>
      </td>
      <td>
        <img src="images/part_5/spheres_p5_rate.png" align="middle" width="400px"/>
        <figcaption>Sample rate image (CBspheres_lambertian.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>


</body>
</html>
